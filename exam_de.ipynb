{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science I\n",
    "### Klausur I im Sommersemester 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Allgemeine Informationen\n",
    "\n",
    "* Sie haben eine Woche Zeit, um die Klausur zu bearbeiten.\n",
    "\n",
    "* Sie können alle Quellen verwenden, müssen sie jedoch korrekt benennen. Wenn Sie ChatGPT oder eine ähnliche Software verwenden, müssen Sie dies kenntlich machen und den verwendeten Prompt angeben.\n",
    "\n",
    "* Sie sollten die folgenden Pakete verwenden: `numpy, pandas, scipy, geopy, scikit-learn/sklearn, matplotlib, seborn, openPyxl` und Pythons Standardlibraries. Diese sind ausreichend, um die Klausur zu lösen. Falls Sie andere Pakete verwenden, rechtfertigen Sie deren Verwendung.\n",
    "\n",
    "* Der Code muss ausreichend kommentiert und verständlich sein. Schreiben Sie Funktionen beim Wiederverwenden von Code. Befolgen Sie im Allgemeinen die Richtlinien aus der Vorlesung. Punkte können aufgrund eines schlecht strukturierten oder unverständlichen Codes abgezogen werden.\n",
    "\n",
    "* **Begründen Sie Entscheidungen** zur Auswahl von Plots, Hypothesentest usw. und **interpretieren Sie** Ihre Ergebnisse.\n",
    "\n",
    "* Sie dürfen in keiner Form Hilfe oder Rat von Dritten in Anspruch nehmen.\n",
    "\n",
    "* Bitte laden Sie Ihre vollständige Lösung der Klausur als `.zip`-Datei mit dem Dateinamen `vorname_matrikelnummer.zip` bis 8. August 2024 um 12:00 Uhr auf StudIP in den Ordner `Submission - Exam 1` hoch.\n",
    "\n",
    "* Fügen Sie der `.zip` Datei auch die unterschriebene Eigenständigkeitserklärung hinzu.\n",
    "\n",
    "* Wenn Sie Fragen haben, kontaktieren Sie uns bitte rechtzeitig über Rocketchat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT LIBRARIES\n",
    "import numpy as np, pandas as pd, scipy, geopy, sklearn, matplotlib, seaborn, openpyxl, warnings, os \n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='openpyxl')\n",
    "\n",
    "# Debug Level\n",
    "# 1 - Loading Data\n",
    "# 2 - Change Loaded Data\n",
    "debug = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgaben und Punkte:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th colspan=\"3\">Aufgabe 1 - Data Preprocessing</th>\n",
    "      <th colspan=\"2\">Aufgabe 2 - Plotting</th>\n",
    "      <th colspan=\"2\">Aufgabe 3 - Statistics</th>\n",
    "      <th colspan=\"2\">Aufgabe 4 - Machine Learning </th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>Aufgabe 1.1</th>\n",
    "      <th>Aufgabe 1.2</th>\n",
    "      <th>Aufgabe 1.3</th>\n",
    "      <th>Aufgabe 2.1</th>\n",
    "      <th>Aufgabe 2.2</th>\n",
    "      <th>Aufgabe 3.1</th>\n",
    "      <th>Aufgabe 3.2</th>\n",
    "      <th>Aufgabe 4.1</th>\n",
    "      <th>Aufgabe 4.2</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>10 Punkte </td>\n",
    "      <td>12 Punkte </td>\n",
    "      <td>2 Punkte </td>\n",
    "      <td>11 Punkte</td>\n",
    "      <td>27 Punkte </td>\n",
    "      <td>13 Punkte </td>\n",
    "      <td>5 Punkte </td>\n",
    "      <td>10 Punkte </td>\n",
    "      <td>10 Punkte </td>\n",
    "    </tr>\n",
    "    <!-- Add more rows as needed -->\n",
    "  </tbody>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "## Aufgabe 0: Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Klausurordner enthält ein `Dockerfile`, in dem alle relevanten Pakete definiert sind. Das `Dockerfile` baut auf dem Jupyter Server Image auf. Verwenden Sie dieses Dockerfile, um zuerst ein Docker Image zu erstellen und dann einen Docker Container von diesem Image zu starten. Benutzen Sie anschließend die Jupyter Server Instanz, um an der Klausur zu arbeiten. Wir empfehlen dringend, die Docker-Umgebung zu verwenden, um Versionskonflikte zwischen den verschiedenen Paketen zu vermeiden. Code, der in dieser Umgebung nicht ausführbar ist, wird als **nicht funktional** bewertet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "## Aufgabe 1: Data Preprocessing (24 Punkte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datenbeschreibung\n",
    "\n",
    "Im Ordner `data` finden Sie die monatlichen Parkdaten der Stadt Göttingen für das Jahr 2023 (Feb.-Dez.). Die Parkschein-Verkäufe an den stationären Parkscheinautomaten befinden sich in den Dateien, deren Namen mit `Cale` beginnt, und die mit der Parkster-App gekauften Parkscheine befinden sich in den Dateien, deren Namen mit `Parkster` beginnen.<br>\n",
    "Die Datei `parkzone_latlong.csv` enthält weitere geografische Informationen zu den Parkzonen und die Datei `psa_latlong.csv` enthält geografische Informationen über die Parkscheinautomaten innerhalb der Parkzone.\n",
    "\n",
    "Die bereitgestellten Parkdaten sind echte Rohdaten und stammen direkt von der Stadt Göttingen. Wir haben lediglich die geografischen Informationen hinzugefügt.\n",
    "\n",
    "*Bitte beachten Sie:*\n",
    "- *Obwohl wir nur Daten von Februar bis Dezember haben, bezeichnen wir diese im Folgenden als jährlich.*\n",
    "- *Aufgrund der Größe der Daten sollten Sie Ihren Arbeitsspeicher effizient verwenden. Vermeiden Sie daher die Speicherung mehrerer Kopien desselben DataFrames.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aufagbe 1.1 - Laden der Daten (10 Punkte)\n",
    "Laden Sie die Dateien für die Parkscheinautomaten (`Cale-*`) und für die App (`Parkster-*`) und fügen Sie diese **jeweils** zu einem Dataframe zusammen, der die jährlichen Verkäufe für Parkscheinautomaten und App beinhaltet. <br>\n",
    "Laden Sie auch die weiteren Informationen zu den Parkscheinautomaten (`psa_latlong.csv`) und Parkzonen (` parkzones_latlong.csv`).\n",
    "\n",
    "Sie werden die Werte `0` und `999` in der Spalte `Automaten -ID` für die Daten der Parkscheinautomaten finden. <br> Ändern Sie die `0`en in `1`en und löschen Sie alle Einträge mit `999`.\n",
    "Überprüfen Sie auch auf Zeilen-Duplikate und löschen Sie diese gegebenenfalls. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load multiple datafiles as one dataframe\n",
    "def load_data_files(filtername, skippingrows=0): # skippingrows are rows to skip\n",
    "    print(f\"{filtername} datafiles loading...\")\n",
    "    data_files = list(filter(lambda x: x.startswith(filtername), os.listdir('data'))) # file searching\n",
    "    data_files_df = pd.concat([pd.read_excel(f\"data/{file}\", skiprows=skippingrows) for file in data_files]) # combine files in dataframe\n",
    "    print(f\"{filtername} datafiles finish\\n===============\")\n",
    "    if debug <= 1: print(data_files_df)\n",
    "    return data_files, data_files_df # return tuple of the files and the dataframe\n",
    "\n",
    "# Function to load file\n",
    "def loadcsv(filename):\n",
    "    print(f\"{filename} loading\")\n",
    "    file_df = pd.read_csv(f'data/{filename}')\n",
    "    print(f\"{filename} finish\\n===============\")\n",
    "    if debug <= 1: print(file_df)\n",
    "    return file_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cale- datafiles loading...\n",
      "Cale- datafiles finish\n",
      "===============\n",
      "      Automat - Automaten ID Zahleinheit - Name     Knoten  \\\n",
      "0                      PA320              Münze  Göttingen   \n",
      "1                       PA03              Münze  Göttingen   \n",
      "2                      PA354              Münze  Göttingen   \n",
      "3                      PA332              Münze  Göttingen   \n",
      "4                      PA334              Münze  Göttingen   \n",
      "...                      ...                ...        ...   \n",
      "68207                   PA85              Münze  Göttingen   \n",
      "68208                   PA85              Münze  Göttingen   \n",
      "68209                   PA85              Münze  Göttingen   \n",
      "68210                   PA85              Münze  Göttingen   \n",
      "68211                   PA84              Münze  Göttingen   \n",
      "\n",
      "           Kaufdatum Lokal  Betrag Artikelname  Artikel ID Tarifpaket - Name  \\\n",
      "0      01.11.2023 00:28:56     1.9  Parkticket           0      Normalticket   \n",
      "1      01.11.2023 00:44:21     4.0  Parkticket           0      Normalticket   \n",
      "2      01.11.2023 03:36:32     5.0  Parkticket           0      Normalticket   \n",
      "3      01.11.2023 05:06:07     4.5  Parkticket           0      Normalticket   \n",
      "4      01.11.2023 05:20:02     5.1  Parkticket           0      Normalticket   \n",
      "...                    ...     ...         ...         ...               ...   \n",
      "68207  04.02.2023 11:45:50     9.0  Parkticket           0      Normalticket   \n",
      "68208  07.02.2023 09:52:12    10.0  Parkticket           0      Normalticket   \n",
      "68209  22.02.2023 08:49:18    10.0  Parkticket           0      Normalticket   \n",
      "68210  07.02.2023 09:50:58    10.2  Parkticket           0      Normalticket   \n",
      "68211  11.02.2023 09:50:41    11.0  Parkticket           0      Normalticket   \n",
      "\n",
      "       Maskierter PAN  Transaktionsreferenz  Ticket Nummer  \n",
      "0                 NaN                   NaN           1848  \n",
      "1                 NaN                   NaN           9103  \n",
      "2                 NaN                   NaN           4500  \n",
      "3                 NaN                   NaN           4074  \n",
      "4                 NaN                   NaN           1218  \n",
      "...               ...                   ...            ...  \n",
      "68207             NaN                   NaN           4604  \n",
      "68208             NaN                   NaN           4658  \n",
      "68209             NaN                   NaN           5036  \n",
      "68210             NaN                   NaN           4657  \n",
      "68211             NaN                   NaN           1576  \n",
      "\n",
      "[708570 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "# data_loading \"Cale-\" skipping row 0 and 1 because of different formatting\n",
    "parking_meters, parking_meters_df = load_data_files(\"Cale-\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parkster- datafiles loading...\n",
      "Parkster- datafiles finish\n",
      "===============\n",
      "       Parkzone             Erstellt                Start  \\\n",
      "0         37008  2023-01-31 13:07:44  2023-01-31 13:07:44   \n",
      "1         37005  2023-01-31 15:40:23  2023-01-31 15:40:23   \n",
      "2         37005  2023-01-31 15:48:59  2023-01-31 15:48:59   \n",
      "3         37204  2023-01-31 15:58:47  2023-01-31 15:58:47   \n",
      "4         37105  2023-01-31 16:08:01  2023-01-31 16:08:00   \n",
      "...         ...                  ...                  ...   \n",
      "40050     37108  2023-12-31 16:45:25  2023-12-31 16:45:25   \n",
      "40051     37001  2023-12-31 17:09:16  2023-12-31 17:09:16   \n",
      "40052     37105  2023-12-31 17:25:59  2023-12-31 17:25:59   \n",
      "40053     37001  2023-12-31 17:52:09  2023-12-31 17:52:09   \n",
      "40054     37108  2023-12-31 20:40:11  2023-12-31 20:40:11   \n",
      "\n",
      "                     Stopp Parkgebühren inkl. MwSt. in EUR     Status  \\\n",
      "0      2023-02-01 14:00:00                            8,31     normal   \n",
      "1      2023-02-01 11:45:19                            4,96     normal   \n",
      "2      2023-02-01 11:34:59                            4,74     normal   \n",
      "3      2023-02-01 15:44:00                            7,53     normal   \n",
      "4      2023-02-01 01:38:00                            4,30     normal   \n",
      "...                    ...                             ...        ...   \n",
      "40050  2023-12-31 17:43:25                             0.0     normal   \n",
      "40051  2023-12-31 19:39:16                             0.0     normal   \n",
      "40052  2023-12-31 19:45:35                             0.0     normal   \n",
      "40053  2023-12-31 17:52:28                             0.0  storniert   \n",
      "40054  2023-12-31 23:10:11                             0.0     normal   \n",
      "\n",
      "      Parkscheinart  Zonencode Eigentümercode  \n",
      "0          Kurzzeit      37008                 \n",
      "1          Kurzzeit      37005                 \n",
      "2          Kurzzeit      37005                 \n",
      "3          Kurzzeit      37204                 \n",
      "4          Kurzzeit      37105                 \n",
      "...             ...        ...            ...  \n",
      "40050      Kurzzeit      37108                 \n",
      "40051      Kurzzeit      37001                 \n",
      "40052      Kurzzeit      37105                 \n",
      "40053      Kurzzeit      37001                 \n",
      "40054      Kurzzeit      37108                 \n",
      "\n",
      "[381307 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# data_loading \"Parkster-\"\n",
    "parkzones, parkzones_df = load_data_files(\"Parkster-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parkzones_latlong.csv loading\n",
      "parkzones_latlong.csv finish\n",
      "===============\n",
      "     latitude  longitude  Zonencode  \\\n",
      "0   51.534248   9.936501      37001   \n",
      "1   51.531270   9.936706      37005   \n",
      "2   51.541762   9.942282      37008   \n",
      "3   51.541249   9.944294      37009   \n",
      "4   51.553603   9.942338      37010   \n",
      "5   51.529542   9.939956      37101   \n",
      "6   51.533104   9.926817      37102   \n",
      "7   51.534678   9.942051      37103   \n",
      "8   51.536634   9.932465      37104   \n",
      "9   51.529205   9.933063      37105   \n",
      "10  51.530127   9.937980      37106   \n",
      "11  51.531365   9.927962      37107   \n",
      "12  51.536733   9.928201      37108   \n",
      "13  51.537675   9.930298      37109   \n",
      "14  51.533859   9.943545      37201   \n",
      "15  51.528115   9.940574      37202   \n",
      "16  51.528164   9.940557      37203   \n",
      "17  51.540630   9.935538      37204   \n",
      "18  51.537585   9.940781      37205   \n",
      "19  51.541593   9.937814      37206   \n",
      "20  51.528780   9.931563      37207   \n",
      "21  51.532833   9.935181      37208   \n",
      "22  51.528850   9.936085      37209   \n",
      "\n",
      "                                              Bereich Höchstparkdauer  \n",
      "0                  Parkzone I - Straßenrandparkplätze       4 Stunden  \n",
      "1                 Parkzone II - Straßenrandparkplätze       4 Stunden  \n",
      "2   Parkzone II - Humboldtallee, Nikolausberger We...       6 Stunden  \n",
      "3                               Parkzone II - Waldweg      11 Stunden  \n",
      "4          Parkzone II - Am Papenberg, Zimmermannstr.     Tagesticket  \n",
      "5              Parkzone I - Parkplatz Am Geismar Tor        4 Stunden  \n",
      "6                 Parkzone I - Parkplatz Bürgerstraße       4 Stunden  \n",
      "7                  Parkzone I - Parkplatz Albaniplatz       8 Stunden  \n",
      "8              Parkzone I - Parkplatz Reitstallstraße       4 Stunden  \n",
      "9         Parkzone I - Parkplatz Bürgerstraße / Juzi        4 Stunden  \n",
      "10                 Parkzone I - Parkplatz Rosengarten      10 Stunden  \n",
      "11            Parkzone I - Parkplatz Voigt Realschule       4 Stunden  \n",
      "12                 Parkzone I - Parkplatz Bahnhof Ost        1 Stunde  \n",
      "13              Parkzone I - Parkplatz Justizbehörden       4 Stunden  \n",
      "14                 Parkzone II - Parkplatz Stadthalle       4 Stunden  \n",
      "15                  Parkzone II - Parkplatz Rathaus I       4 Stunden  \n",
      "16    Parkzone II - Parkplatz Rathaus II + Tiefgarage       4 Stunden  \n",
      "17  Parkzone II - Parkplatz Platz der Göttinger Si...       8 Stunden  \n",
      "18         Parkzone II - Parkplatz M-P-G / Sporthalle       8 Stunden  \n",
      "19               Parkzone II - Parkplatz Goßlerstraße       8 Stunden  \n",
      "20        Parkzone II - Parkplatz FKG Bürgerstraße 36       4 Stunden  \n",
      "21  Parkzone II - Parkplatz Landkreis (Freitags ab...       4 Stunden  \n",
      "22  Parkzone II - Parkplatz Bonifatiusschule I (nu...       4 Stunden  \n"
     ]
    }
   ],
   "source": [
    "parkzones_latlong_df = loadcsv(\"parkzones_latlong.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "psa_latlong.csv loading\n",
      "psa_latlong.csv finish\n",
      "===============\n",
      "       PSA                 location   latitude  longitude   zone\n",
      "0        1           Am Geismar Tor  51.529542   9.939956  37101\n",
      "1    1 - 2           Am Geismar Tor  51.529542   9.939956  37101\n",
      "2        2             Bürgerstraße  51.533104   9.926817  37102\n",
      "3        3                Papendiek  51.533827   9.931693  37001\n",
      "4        4       Bonifatiusschule -  51.528850   9.936085  37209\n",
      "..     ...                      ...        ...        ...    ...\n",
      "199    358          Kreuzbergring 2  51.542319   9.932972  37008\n",
      "200    359          Kreuzbergring 3  51.542898   9.933473  37008\n",
      "201    360  Von - Siebold- Straße 1  51.545994   9.943523  37008\n",
      "202    361  Von - Siebold- Straße 2  51.546472   9.943674  37008\n",
      "203    362  Von - Siebold- Straße 3  51.545665   9.942838  37008\n",
      "\n",
      "[204 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "psa_latlong_df = loadcsv(\"psa_latlong.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Automat - Automaten ID Zahleinheit - Name     Knoten  \\\n",
      "0                         320              Münze  Göttingen   \n",
      "1                           3              Münze  Göttingen   \n",
      "2                         354              Münze  Göttingen   \n",
      "3                         332              Münze  Göttingen   \n",
      "4                         334              Münze  Göttingen   \n",
      "...                       ...                ...        ...   \n",
      "68207                      85              Münze  Göttingen   \n",
      "68208                      85              Münze  Göttingen   \n",
      "68209                      85              Münze  Göttingen   \n",
      "68210                      85              Münze  Göttingen   \n",
      "68211                      84              Münze  Göttingen   \n",
      "\n",
      "           Kaufdatum Lokal  Betrag Artikelname  Artikel ID Tarifpaket - Name  \\\n",
      "0      01.11.2023 00:28:56     1.9  Parkticket           0      Normalticket   \n",
      "1      01.11.2023 00:44:21     4.0  Parkticket           0      Normalticket   \n",
      "2      01.11.2023 03:36:32     5.0  Parkticket           0      Normalticket   \n",
      "3      01.11.2023 05:06:07     4.5  Parkticket           0      Normalticket   \n",
      "4      01.11.2023 05:20:02     5.1  Parkticket           0      Normalticket   \n",
      "...                    ...     ...         ...         ...               ...   \n",
      "68207  04.02.2023 11:45:50     9.0  Parkticket           0      Normalticket   \n",
      "68208  07.02.2023 09:52:12    10.0  Parkticket           0      Normalticket   \n",
      "68209  22.02.2023 08:49:18    10.0  Parkticket           0      Normalticket   \n",
      "68210  07.02.2023 09:50:58    10.2  Parkticket           0      Normalticket   \n",
      "68211  11.02.2023 09:50:41    11.0  Parkticket           0      Normalticket   \n",
      "\n",
      "       Maskierter PAN  Transaktionsreferenz  Ticket Nummer  \n",
      "0                 NaN                   NaN           1848  \n",
      "1                 NaN                   NaN           9103  \n",
      "2                 NaN                   NaN           4500  \n",
      "3                 NaN                   NaN           4074  \n",
      "4                 NaN                   NaN           1218  \n",
      "...               ...                   ...            ...  \n",
      "68207             NaN                   NaN           4604  \n",
      "68208             NaN                   NaN           4658  \n",
      "68209             NaN                   NaN           5036  \n",
      "68210             NaN                   NaN           4657  \n",
      "68211             NaN                   NaN           1576  \n",
      "\n",
      "[708570 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ID Sortierung in Ints um bessere Übersicht zu haben.\n",
    "parking_meters_df['Automat - Automaten ID'] = parking_meters_df['Automat - Automaten ID'].str.replace(\"PA\", \"\").astype(int)\n",
    "if debug <= 2: print(parking_meters_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Parkzone             Erstellt                Start  \\\n",
      "0         37008  2023-01-31 13:07:44  2023-01-31 13:07:44   \n",
      "1         37005  2023-01-31 15:40:23  2023-01-31 15:40:23   \n",
      "2         37005  2023-01-31 15:48:59  2023-01-31 15:48:59   \n",
      "3         37204  2023-01-31 15:58:47  2023-01-31 15:58:47   \n",
      "4         37105  2023-01-31 16:08:01  2023-01-31 16:08:00   \n",
      "...         ...                  ...                  ...   \n",
      "40050     37108  2023-12-31 16:45:25  2023-12-31 16:45:25   \n",
      "40051     37001  2023-12-31 17:09:16  2023-12-31 17:09:16   \n",
      "40052     37105  2023-12-31 17:25:59  2023-12-31 17:25:59   \n",
      "40053     37001  2023-12-31 17:52:09  2023-12-31 17:52:09   \n",
      "40054     37108  2023-12-31 20:40:11  2023-12-31 20:40:11   \n",
      "\n",
      "                     Stopp  Parkgebühren inkl. MwSt. in EUR     Status  \\\n",
      "0      2023-02-01 14:00:00                             8.31     normal   \n",
      "1      2023-02-01 11:45:19                             4.96     normal   \n",
      "2      2023-02-01 11:34:59                             4.74     normal   \n",
      "3      2023-02-01 15:44:00                             7.53     normal   \n",
      "4      2023-02-01 01:38:00                             4.30     normal   \n",
      "...                    ...                              ...        ...   \n",
      "40050  2023-12-31 17:43:25                              NaN     normal   \n",
      "40051  2023-12-31 19:39:16                              NaN     normal   \n",
      "40052  2023-12-31 19:45:35                              NaN     normal   \n",
      "40053  2023-12-31 17:52:28                              NaN  storniert   \n",
      "40054  2023-12-31 23:10:11                              NaN     normal   \n",
      "\n",
      "      Parkscheinart  Zonencode Eigentümercode  \n",
      "0          Kurzzeit      37008                 \n",
      "1          Kurzzeit      37005                 \n",
      "2          Kurzzeit      37005                 \n",
      "3          Kurzzeit      37204                 \n",
      "4          Kurzzeit      37105                 \n",
      "...             ...        ...            ...  \n",
      "40050      Kurzzeit      37108                 \n",
      "40051      Kurzzeit      37001                 \n",
      "40052      Kurzzeit      37105                 \n",
      "40053      Kurzzeit      37001                 \n",
      "40054      Kurzzeit      37108                 \n",
      "\n",
      "[381307 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert MwSt to float\n",
    "parkzones_df['Parkgebühren inkl. MwSt. in EUR'] = parkzones_df['Parkgebühren inkl. MwSt. in EUR'].str.replace(',', '.').astype(float) \n",
    "if debug <= 2: print(parkzones_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parkzone</th>\n",
       "      <th>Erstellt</th>\n",
       "      <th>Start</th>\n",
       "      <th>Stopp</th>\n",
       "      <th>Parkgebühren inkl. MwSt. in EUR</th>\n",
       "      <th>Status</th>\n",
       "      <th>Parkscheinart</th>\n",
       "      <th>Zonencode</th>\n",
       "      <th>Eigentümercode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37008</td>\n",
       "      <td>2023-01-31 13:07:44</td>\n",
       "      <td>2023-01-31 13:07:44</td>\n",
       "      <td>2023-02-01 14:00:00</td>\n",
       "      <td>8.31</td>\n",
       "      <td>normal</td>\n",
       "      <td>Kurzzeit</td>\n",
       "      <td>37008</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37005</td>\n",
       "      <td>2023-01-31 15:40:23</td>\n",
       "      <td>2023-01-31 15:40:23</td>\n",
       "      <td>2023-02-01 11:45:19</td>\n",
       "      <td>4.96</td>\n",
       "      <td>normal</td>\n",
       "      <td>Kurzzeit</td>\n",
       "      <td>37005</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37005</td>\n",
       "      <td>2023-01-31 15:48:59</td>\n",
       "      <td>2023-01-31 15:48:59</td>\n",
       "      <td>2023-02-01 11:34:59</td>\n",
       "      <td>4.74</td>\n",
       "      <td>normal</td>\n",
       "      <td>Kurzzeit</td>\n",
       "      <td>37005</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37204</td>\n",
       "      <td>2023-01-31 15:58:47</td>\n",
       "      <td>2023-01-31 15:58:47</td>\n",
       "      <td>2023-02-01 15:44:00</td>\n",
       "      <td>7.53</td>\n",
       "      <td>normal</td>\n",
       "      <td>Kurzzeit</td>\n",
       "      <td>37204</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37105</td>\n",
       "      <td>2023-01-31 16:08:01</td>\n",
       "      <td>2023-01-31 16:08:00</td>\n",
       "      <td>2023-02-01 01:38:00</td>\n",
       "      <td>4.30</td>\n",
       "      <td>normal</td>\n",
       "      <td>Kurzzeit</td>\n",
       "      <td>37105</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40050</th>\n",
       "      <td>37108</td>\n",
       "      <td>2023-12-31 16:45:25</td>\n",
       "      <td>2023-12-31 16:45:25</td>\n",
       "      <td>2023-12-31 17:43:25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>Kurzzeit</td>\n",
       "      <td>37108</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40051</th>\n",
       "      <td>37001</td>\n",
       "      <td>2023-12-31 17:09:16</td>\n",
       "      <td>2023-12-31 17:09:16</td>\n",
       "      <td>2023-12-31 19:39:16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>Kurzzeit</td>\n",
       "      <td>37001</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40052</th>\n",
       "      <td>37105</td>\n",
       "      <td>2023-12-31 17:25:59</td>\n",
       "      <td>2023-12-31 17:25:59</td>\n",
       "      <td>2023-12-31 19:45:35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>Kurzzeit</td>\n",
       "      <td>37105</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40053</th>\n",
       "      <td>37001</td>\n",
       "      <td>2023-12-31 17:52:09</td>\n",
       "      <td>2023-12-31 17:52:09</td>\n",
       "      <td>2023-12-31 17:52:28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>storniert</td>\n",
       "      <td>Kurzzeit</td>\n",
       "      <td>37001</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40054</th>\n",
       "      <td>37108</td>\n",
       "      <td>2023-12-31 20:40:11</td>\n",
       "      <td>2023-12-31 20:40:11</td>\n",
       "      <td>2023-12-31 23:10:11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>Kurzzeit</td>\n",
       "      <td>37108</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>381278 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Parkzone             Erstellt                Start  \\\n",
       "0         37008  2023-01-31 13:07:44  2023-01-31 13:07:44   \n",
       "1         37005  2023-01-31 15:40:23  2023-01-31 15:40:23   \n",
       "2         37005  2023-01-31 15:48:59  2023-01-31 15:48:59   \n",
       "3         37204  2023-01-31 15:58:47  2023-01-31 15:58:47   \n",
       "4         37105  2023-01-31 16:08:01  2023-01-31 16:08:00   \n",
       "...         ...                  ...                  ...   \n",
       "40050     37108  2023-12-31 16:45:25  2023-12-31 16:45:25   \n",
       "40051     37001  2023-12-31 17:09:16  2023-12-31 17:09:16   \n",
       "40052     37105  2023-12-31 17:25:59  2023-12-31 17:25:59   \n",
       "40053     37001  2023-12-31 17:52:09  2023-12-31 17:52:09   \n",
       "40054     37108  2023-12-31 20:40:11  2023-12-31 20:40:11   \n",
       "\n",
       "                     Stopp  Parkgebühren inkl. MwSt. in EUR     Status  \\\n",
       "0      2023-02-01 14:00:00                             8.31     normal   \n",
       "1      2023-02-01 11:45:19                             4.96     normal   \n",
       "2      2023-02-01 11:34:59                             4.74     normal   \n",
       "3      2023-02-01 15:44:00                             7.53     normal   \n",
       "4      2023-02-01 01:38:00                             4.30     normal   \n",
       "...                    ...                              ...        ...   \n",
       "40050  2023-12-31 17:43:25                              NaN     normal   \n",
       "40051  2023-12-31 19:39:16                              NaN     normal   \n",
       "40052  2023-12-31 19:45:35                              NaN     normal   \n",
       "40053  2023-12-31 17:52:28                              NaN  storniert   \n",
       "40054  2023-12-31 23:10:11                              NaN     normal   \n",
       "\n",
       "      Parkscheinart  Zonencode Eigentümercode  \n",
       "0          Kurzzeit      37008                 \n",
       "1          Kurzzeit      37005                 \n",
       "2          Kurzzeit      37005                 \n",
       "3          Kurzzeit      37204                 \n",
       "4          Kurzzeit      37105                 \n",
       "...             ...        ...            ...  \n",
       "40050      Kurzzeit      37108                 \n",
       "40051      Kurzzeit      37001                 \n",
       "40052      Kurzzeit      37105                 \n",
       "40053      Kurzzeit      37001                 \n",
       "40054      Kurzzeit      37108                 \n",
       "\n",
       "[381278 rows x 9 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0s in 1s\n",
    "parking_meters_df['Automat - Automaten ID'] = parking_meters_df['Automat - Automaten ID'].replace(0, 1)\n",
    "\n",
    "# Drop Entry 999\n",
    "parking_meters_df = parking_meters_df[parking_meters_df['Automat - Automaten ID'] != 999]\n",
    "\n",
    "# Drop Duplicates\n",
    "parking_meters_df.drop_duplicates()\n",
    "parkzones_df.drop_duplicates()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aufgabe 1.2 - Zusammenführen und Formatieren (12 Punkte)\n",
    "Erstellen Sie einen DataFrame für beide Verkaufsarten, indem Sie die beiden zuvor erstellen DataFrames zusammenführen. Nutzen Sie dazu die Parkzonen Informationen *(in `parkzones_latlong.csv`)* und die Parkscheinautomatennummer *(in` pa_latlong.csv`)*. Stellen Sie sicher, dass sich in Ihrem DataFrame die geografischen Informationen für Parkscheinautomaten und Parkzonen befinden.\n",
    "Verwenden Sie die Spalten `Kaufdatum Lokal` und `Start` für das Kaufdatum, codieren Sie die Spalte als `datetime`-Objekt und verwenden Sie sie als Indexspalte. Stellen Sie außerdem sicher, dass die anderen Spalten ein angemessenes Datenformat haben.\n",
    "\n",
    "*Hinweis: Es ist zu erwarten, dass `Nan`-Werte für einige Spalten in den Zeilen zu Appkäufen auftauchen.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataStructure Creation\n",
    "park_data = {\n",
    "    'time': 'datetime64[ns]',\n",
    "    'machine_ID': 'Int64',\n",
    "    'fee': 'float64',\n",
    "    'category': 'object',\n",
    "    'street': 'object',\n",
    "    'latitude_machine': 'float64',\n",
    "    'longitude_machine': 'float64',\n",
    "    'zone': 'int64',\n",
    "    'latitude_zone': 'float64',\n",
    "    'longitude_zone': 'float64'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Um das mergen einfacher zu machen\n",
    "parking_meters_df['Automat - Automaten ID'] = parking_meters_df['Automat - Automaten ID'].astype(str)\n",
    "psa_latlong_df['PSA'] = psa_latlong_df['PSA'].astype(str)\n",
    "parkzones_df['Zonencode'] = parkzones_df['Parkzone'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_psa_df = pd.merge(parking_meters_df, psa_latlong_df, how='left', left_on='Automat - Automaten ID', right_on='PSA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_psa_df['Kaufdatum Lokal'] = pd.to_datetime(merged_psa_df['Kaufdatum Lokal'], format='%d.%m.%Y %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parkscheinautomaten-Daten mit geografischen Informationen zusammenführen\n",
    "merged_psa_df = pd.merge(parking_meters_df, psa_latlong_df, how='left', left_on='Automat - Automaten ID', right_on='PSA')\n",
    "\n",
    "\n",
    "# Parkzonen-Daten mit geografischen Informationen zusammenführen\n",
    "merged_parkzones_df = pd.merge(parkzones_df, parkzones_latlong_df, how='left', left_on='Parkzone', right_on='Zonencode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "':' is a bad directive in format '%Y-%m-%d %H:%:M:%S'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32mstrptime.pyx:230\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime._get_format_regex\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/usr/lib/python3.10/_strptime.py:263\u001b[0m, in \u001b[0;36mTimeRE.compile\u001b[0;34m(self, format)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return a compiled re object for the format string.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 263\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m re_compile(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpattern\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m, IGNORECASE)\n",
      "File \u001b[0;32m/usr/lib/python3.10/_strptime.py:257\u001b[0m, in \u001b[0;36mTimeRE.pattern\u001b[0;34m(self, format)\u001b[0m\n\u001b[1;32m    254\u001b[0m directive_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    255\u001b[0m processed_format \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (processed_format,\n\u001b[1;32m    256\u001b[0m                                \u001b[38;5;28mformat\u001b[39m[:directive_index\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m--> 257\u001b[0m                                \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mdirective_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mformat\u001b[39m[directive_index\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m:]\n",
      "File \u001b[0;32mstrptime.pyx:974\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.TimeRE.__getitem__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: ':'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Spalten in datetime-Objekte konvertieren\u001b[39;00m\n\u001b[1;32m      2\u001b[0m merged_psa_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKaufdatum Lokal\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(merged_psa_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKaufdatum Lokal\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm.\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m merged_parkzones_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStart\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmerged_parkzones_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mStart\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mY-\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mm-\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mH:\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m:M:\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mS\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/tools/datetimes.py:1067\u001b[0m, in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m   1065\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mmap(cache_array)\n\u001b[1;32m   1066\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1067\u001b[0m         values \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1068\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39m_constructor(values, index\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mindex, name\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1069\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, (ABCDataFrame, abc\u001b[38;5;241m.\u001b[39mMutableMapping)):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/tools/datetimes.py:433\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;66;03m# `format` could be inferred, or user didn't ask for mixed-format parsing.\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_array_strptime_with_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    435\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m objects_to_datetime64(\n\u001b[1;32m    436\u001b[0m     arg,\n\u001b[1;32m    437\u001b[0m     dayfirst\u001b[38;5;241m=\u001b[39mdayfirst,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    441\u001b[0m     allow_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    442\u001b[0m )\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/tools/datetimes.py:467\u001b[0m, in \u001b[0;36m_array_strptime_with_fallback\u001b[0;34m(arg, name, utc, fmt, exact, errors)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_array_strptime_with_fallback\u001b[39m(\n\u001b[1;32m    457\u001b[0m     arg,\n\u001b[1;32m    458\u001b[0m     name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    462\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    463\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Index:\n\u001b[1;32m    464\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;124;03m    Call array_strptime, with fallback behavior depending on 'errors'.\u001b[39;00m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 467\u001b[0m     result, tz_out \u001b[38;5;241m=\u001b[39m \u001b[43marray_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tz_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    469\u001b[0m         unit \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdatetime_data(result\u001b[38;5;241m.\u001b[39mdtype)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32mstrptime.pyx:340\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mstrptime.pyx:220\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime._get_format_regex\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mstrptime.pyx:238\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime._get_format_regex\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: ':' is a bad directive in format '%Y-%m-%d %H:%:M:%S'"
     ]
    }
   ],
   "source": [
    "# Spalten in datetime-Objekte konvertieren\n",
    "merged_psa_df['Kaufdatum Lokal'] = pd.to_datetime(merged_psa_df['Kaufdatum Lokal'], format='%d-%m-%Y %H:%M:%S')\n",
    "merged_parkzones_df['Start'] = pd.to_datetime(merged_parkzones_df['Start'], format='%Y-%m-%d %H:%:M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aufgabe 1.3 - DataFrame Check (2 Punkte)\n",
    "Der bereinigte und vollständige DataFrame für die folgenden Aufgaben sollte der Datei `data/clean_dataframe.csv` entsprechen, der wie folgt eingelesen werden kann:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>machine_ID</th>\n",
       "      <th>fee</th>\n",
       "      <th>category</th>\n",
       "      <th>street</th>\n",
       "      <th>latitude_machine</th>\n",
       "      <th>longitude_machine</th>\n",
       "      <th>zone</th>\n",
       "      <th>latitude_zone</th>\n",
       "      <th>longitude_zone</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-01-31 13:07:44</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>8.31</td>\n",
       "      <td>app</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37008</td>\n",
       "      <td>51.541762</td>\n",
       "      <td>9.942282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-31 15:40:23</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>4.96</td>\n",
       "      <td>app</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37005</td>\n",
       "      <td>51.531270</td>\n",
       "      <td>9.936706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-31 15:48:59</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>4.74</td>\n",
       "      <td>app</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37005</td>\n",
       "      <td>51.531270</td>\n",
       "      <td>9.936706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-31 15:58:47</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>7.53</td>\n",
       "      <td>app</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37204</td>\n",
       "      <td>51.540630</td>\n",
       "      <td>9.935538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-31 16:08:00</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>4.30</td>\n",
       "      <td>app</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37105</td>\n",
       "      <td>51.529205</td>\n",
       "      <td>9.933063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31 16:45:25</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.00</td>\n",
       "      <td>app</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37108</td>\n",
       "      <td>51.536733</td>\n",
       "      <td>9.928201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31 17:09:16</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.00</td>\n",
       "      <td>app</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37001</td>\n",
       "      <td>51.534248</td>\n",
       "      <td>9.936501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31 17:25:59</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.00</td>\n",
       "      <td>app</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37105</td>\n",
       "      <td>51.529205</td>\n",
       "      <td>9.933063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31 17:52:09</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.00</td>\n",
       "      <td>app</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37001</td>\n",
       "      <td>51.534248</td>\n",
       "      <td>9.936501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31 20:40:11</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.00</td>\n",
       "      <td>app</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37108</td>\n",
       "      <td>51.536733</td>\n",
       "      <td>9.928201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1089846 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     machine_ID   fee category street  latitude_machine  \\\n",
       "time                                                                      \n",
       "2023-01-31 13:07:44        <NA>  8.31      app    NaN               NaN   \n",
       "2023-01-31 15:40:23        <NA>  4.96      app    NaN               NaN   \n",
       "2023-01-31 15:48:59        <NA>  4.74      app    NaN               NaN   \n",
       "2023-01-31 15:58:47        <NA>  7.53      app    NaN               NaN   \n",
       "2023-01-31 16:08:00        <NA>  4.30      app    NaN               NaN   \n",
       "...                         ...   ...      ...    ...               ...   \n",
       "2023-12-31 16:45:25        <NA>  0.00      app    NaN               NaN   \n",
       "2023-12-31 17:09:16        <NA>  0.00      app    NaN               NaN   \n",
       "2023-12-31 17:25:59        <NA>  0.00      app    NaN               NaN   \n",
       "2023-12-31 17:52:09        <NA>  0.00      app    NaN               NaN   \n",
       "2023-12-31 20:40:11        <NA>  0.00      app    NaN               NaN   \n",
       "\n",
       "                     longitude_machine   zone  latitude_zone  longitude_zone  \n",
       "time                                                                          \n",
       "2023-01-31 13:07:44                NaN  37008      51.541762        9.942282  \n",
       "2023-01-31 15:40:23                NaN  37005      51.531270        9.936706  \n",
       "2023-01-31 15:48:59                NaN  37005      51.531270        9.936706  \n",
       "2023-01-31 15:58:47                NaN  37204      51.540630        9.935538  \n",
       "2023-01-31 16:08:00                NaN  37105      51.529205        9.933063  \n",
       "...                                ...    ...            ...             ...  \n",
       "2023-12-31 16:45:25                NaN  37108      51.536733        9.928201  \n",
       "2023-12-31 17:09:16                NaN  37001      51.534248        9.936501  \n",
       "2023-12-31 17:25:59                NaN  37105      51.529205        9.933063  \n",
       "2023-12-31 17:52:09                NaN  37001      51.534248        9.936501  \n",
       "2023-12-31 20:40:11                NaN  37108      51.536733        9.928201  \n",
       "\n",
       "[1089846 rows x 9 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('data/clean_dataframe.csv', parse_dates=['time'], index_col='time', dtype={'machine_ID': 'Int64', \n",
    "                                                                           'fee': 'float64', \n",
    "                                                                           'category': 'object', \n",
    "                                                                           'street': 'object', \n",
    "                                                                           'latitude_machine': 'float64', \n",
    "                                                                           'longitude_machine': 'float64', \n",
    "                                                                           'zone': 'int64', \n",
    "                                                                           'latitude_zone': 'float64', \n",
    "                                                                           'longitude_zone': 'float64'}).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stellen Sie sicher, dass Ihr DataFrame mit `clean_dataframe.csv` übereinstimmt. Verwenden Sie dazu die Funktion [`pandas.DataFrame.equals`](https://pandas.pydata.org/docs/reference/api/pandas.dataframe.equals.html).\n",
    "\n",
    "Sollte `pandas.DataFrame.equals` nach Ihren Anpassungen nicht `True` zurückgeben, arbeiten Sie bitte mit `clean_dataframe.csv` weiter und geben Sie dies in einer Markdown-Zelle an. In diesem Fall erhalten Sie keine Punkte für die Teilaufgabe 1.3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "## Aufgabe 2: Plotting (38 Punkte)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 2.1 - Analyse der Parkscheinautomaten (11 Punkte)\n",
    "Die Stadt Göttingen möchte einen Überblick über die Umsätze der einzelnen **Parkscheinautomaten** erhalten und stellt Sie für eine anfängliche explorative Analyse des Verkaufsvolumens und der geografischen Anordnung der Automaten ein."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 (6 Punkte)\n",
    "Finden Sie die fünf umsatzstärksten Parkscheinautomaten im Jahr 2023 und visualisieren Sie den **wöchentlichen** Umsatz im Laufe des Jahres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 (5 Punkte)\n",
    "Der Standort der Parkscheinautomaten könnte auch einen Einfluss auf deren Umsatz haben.\n",
    "\n",
    "Machen Sie sich mit der Funktion `plot_map` aus der Bibliothek `dsplotter` vertraut. Verwenden Sie die Funktion, um den jährlichen Umsatz für jeden Automaten auf einer Karte zu visualisieren. Machen Sie die Farbe **und** den Radius der Standortmarkierung abhängig vom jährlichen Umsatz. Was haben Automaten mit einem hohen jährlichen Umsatz gemeinsam?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 2.2 - Analyse der Automaten- und Appnutzung pro Parkzone (27 Punkte)\n",
    "Im Rahmen der Digitalisierungsinitiative der Stadt wurde die Parkster-App vor einigen Jahren als Alternative zu Parkscheinautomaten eingeführt.\n",
    "Bisher wurden nur die Parkscheinautomaten in die Analyse eingeschlossen und daher einen Großteil des Ticketverkaufs, der über die App stattfand, nicht beachtet.\n",
    "\n",
    "Die Stadt möchte für 2023 eine erste visuelle Analyse der Akzeptanz der App in den einzelnen Parkzonen durchführen und anschließend den gesamten Umsatz analysieren.\n",
    "\n",
    "*Hinweis: Beachten Sie, dass wir die Umsätze aus der Appnutzung nur einschließen können, indem wir die Gesamtauswertung auf Ebene der Parkzonen durchführen.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 (6 Punkte)\n",
    "Bevorzugen Parkende die App- oder die Parkscheinautomatennutzung? \n",
    "\n",
    "Verwenden Sie einen geeigneten Plot, um die durchschnittliche Automaten- bzw. Appnutzungsrate pro **Parkzone** für das gesamte Jahr 2023 zu visualisieren. Was können Sie dem Plot entnehmen?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 (9 Punkte)\n",
    "Wie stark werden die einzelnen Parkzonen genutzt? \n",
    "\n",
    "Visualisieren Sie die Gesamtzahl der Verkäufe und die Automaten- bzw. Appnutzungrate für jede Parkzone im Jahr 2023 **in einem Diagramm**. Verwenden Sie für die y-Achse eine `log`-Skalierung. Was können Sie dem Plot entnehmen?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.3 (7 Punkte)\n",
    "Der vorherige Plot gibt uns eine Vorstellung von der Gesamtzahl der Parktickets *pro Parkzone*. Diese korreliert sehr wahrscheinlich stark mit der Anzahl der Parkplätze pro Zone. Um Parkzonen mit einer unterschiedlichen Anzahl an Parkplätzen zu vergleichen, sollten wir diese mithilfe der Anzahl der verfügbaren Parkplätze je Zone relativieren. Auf diese Weise können wir herausfinden, welche Zonen, relativ zu ihrer Größe, am häufigsten verwendet werden. Da wir nicht die Anzahl der Parkplätze für jede Zone zur Verfügung haben, können wir nur die Anzahl der Parkscheinautomaten als grobe Annäherung verwenden. \n",
    "\n",
    "Verwenden Sie die Informationen aus `psa_latlong.csv` und reproduzieren Sie den vorherigen mit Plot der Gesamtzahl der Verkäufe pro Automat für jede Parkzone. Verwenden Sie für die y-Achse eine `log`-Skalierung. Welche Parkzone wird am meisten genutzt?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.4 (5 Punkte)\n",
    "Bisher haben wir die geografischen Informationen der Parkzonen nicht mit einbezogen. \n",
    "\n",
    "Verwenden Sie erneut die Funktion `plot_map`, um den Standort aller Parkzonen, ihre durchschnittlichen Tickets pro Automat und die Automaten- bzw. Appnutzungsrate zu visualieren. Färben Sie den Kartenmarker mithilfe der Automaten- bzw. Appnutzungsrate und legen Sie den Radius mit den durschnittlich verkauften Tickets pro Automat fest. Was können Sie der Darstellung entnehmen?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aufgabe 3: Statistics (18 Punkte)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aufgabe 3.1 - t-Test (13 Punkte)\n",
    "Zusätzlich zu der visuellen Analyse möchte die Stadt nun auch eine statistische Untersuchung der Verwendung von Parkscheinautomaten und Apps durchführen.\n",
    "\n",
    "Bestimmen Sie dazu zunächst die Automaten- bzw. Appnutzungsrate pro Parkzone für jeden Kalendertag. Führen Sie anschließend für **jede Parkzone** einen t-Test durch, der testet, ob Parkende es vorziehen die App in der jeweiligen Zone zu verwenden. Schreiben Sie das entsprechende Hypothesenpaar auf, führen Sie den Test durch und interpretieren Sie Ihre Testergebnisse. Verwenden Sie für Ihre Testentscheidung ein Signifikanzniveau von 0.05. Welche grundlegende Annahme von statistischen Tests könnte bei diesem Vorgehen verletzt werden?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aufgabe 3.2 - Statistisches Verständnis (5 Punkte)\n",
    "Angenommen, für die Zone `37106` beträgt die durchschnittliche Automaten- bzw. Appnutzungsrate `0.5`.\n",
    "Die Stadt sendet Ihnen die Daten für 2024. \n",
    "\n",
    "An wie vielen Tagen können Sie erwarten, dass die Appnutzung signifikant höher ist, wenn Sie weiterhin von einem Signifikanzniveau von `0.05` ausgehen? Erklären Sie, warum dies der Fall ist. Nehmen Sie an, dass sich das Verhalten der Parkenden im Vergleich zu 2023 nicht geändert hat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aufgabe 4: Machine Learning (20 Punkte)\n",
    "\n",
    "Nutzen Sie ein K-Nearest-Neighbors (KNN) Modell, um die Automaten- bzw. Appnutzungsrate mithilfe des Standortes (`latitude`, `longitude`) und der Parkgebühr (`fee`) vorherzusagen. Verwenden Sie ausschließlich Datenreihen mit Parkgebühren zwischen 2 Euro und 7 Euro.\n",
    "\n",
    "#### Aufgabe 4.1 - Modell-Training and Hyperparameter-Suche (10 Punkte)\n",
    "Bereiten Sie die Daten sinnvoll auf, führen Sie eine Hyperparameter-Suche nach optimalem K-Wert aus, visualisieren Sie die Ergebnisse der Hyperparameter-Suche und verwenden Sie schließlich Ihren optimalen K-Wert, um das Modell zu trainieren.\n",
    "\n",
    "*Hinweis: Verwenden Sie 30% aller Daten zur Bestimmung des optimalen K-Wertes, um die Hyperparameter-Suche zu beschleunigen, und den gesamten Datensatz für das Modell-Training.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aufgabe 4.2 - Visualisierung der Modell-Vorhersage (10 Punkte)\n",
    "Erstellen Sie ein `100 x 100` Grid aus Längen-/Breitengradwerten unter Verwendung der minimalen und maximalen Werte in Ihrem Datensatz. Visualisieren Sie die Vorhersagen des KNN-Modells **für drei verschiedene Parkgebühren** - 3, 5 und 7 Euro. Verwenden Sie dazu die Funktion `plot_map`. Färben Sie den Marker entsprechend der Modell-Vorhersage. Beschreiben Sie mindestens 2 visuelle Veränderungen des vorhergesagten Nutzungsmusters auf der Karte."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
