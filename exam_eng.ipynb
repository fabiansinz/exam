{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exam Data Science I  \n",
    "### Exam I in the Summer Term 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Information\n",
    "\n",
    "* You have one week to complete the exam. \n",
    "\n",
    "* You can use all sources freely, but you must name them correctly. If you use ChatGPT or similar software, you must include the prompt.\n",
    "\n",
    "* You should use the following packages: `numpy, pandas, scipy, geopy, scikit-learn/sklearn, matplotlib, seaborn, openpyxl` and Python's native libraries. These are sufficient to solve the exam. If you use other libraries, justify their use.\n",
    "\n",
    "* Code must be sufficiently commented to be understandable. Write functions whenever you reuse code. In general, follow the guidelines from the lecture. Points may be deducted due to poorly structured or incomprehensible code.\n",
    "\n",
    "* **Always justify (!)** decisions regarding the choice of plots, hypothesis tests, etc. in writing and **interpret** your results.\n",
    "\n",
    "* You are **not** allowed to seek help or advice from other people in any way. \n",
    "\n",
    "* Please submit the complete repository as a `.zip` file with the name `surname_matrikelnummer.zip` by August 8th, 2024 at 12:00 noon on StudIP to the folder `Submission - Exam 1`.\n",
    "\n",
    "* Also add the signed code of conduct to the `.zip` file. \n",
    "\n",
    "* If you have any questions, please contact us via Rocketchat in a timely manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT LIBRARIES\n",
    "import ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises and Points:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th colspan=\"3\">Exercise 1 - Data Preprocessing</th>\n",
    "      <th colspan=\"2\">Exercise 2 - Plotting</th>\n",
    "      <th colspan=\"2\">Exercise 3 - Statistics</th>\n",
    "      <th colspan=\"2\">Exercise 4 - Machine Learning </th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>Exercise 1.1</th>\n",
    "      <th>Exercise 1.2</th>\n",
    "      <th>Exercise 1.3</th>\n",
    "      <th>Exercise 2.1</th>\n",
    "      <th>Exercise 2.2</th>\n",
    "      <th>Exercise 3.1</th>\n",
    "      <th>Exercise 3.2</th>\n",
    "      <th>Exercise 4.1</th>\n",
    "      <th>Exercise 4.2</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>10 points </td>\n",
    "      <td>12 points </td>\n",
    "      <td>2 points </td>\n",
    "      <td>11 points</td>\n",
    "      <td>27 points </td>\n",
    "      <td>13 points </td>\n",
    "      <td>5 points </td>\n",
    "      <td>10 points </td>\n",
    "      <td>10 points </td>\n",
    "    </tr>\n",
    "    <!-- Add more rows as needed -->\n",
    "  </tbody>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "## Exercise 0: Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The exam folder contains a `Dockerfile` in which all relevant libraries are defined. The `Dockerfile` builds up on the Jupyter Server image. Use this Dockerfile to first create a Docker image and then start a Docker container from that image. Afterwards log into the Jupyter Server instance to work on the exam. We strongly recommend using the Docker environment to avoid version conflicts between the various libraries. Code that does not run in this environment will be graded as **non functional**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "## Exercise 1: Data Preprocessing (24 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Description\n",
    "\n",
    "In the data folder, you will find the parking data in Göttingen city for the year 2023 as one file per month. The parking tickets bought using the stationary ticket machines are in the files whose names start with `Cale` and the parking tickets bought with the parkster app are in the files whose names start with `Parkster`. <br> \n",
    "The file `parkzone_latlong.csv` provides further geographical information regarding the parkzones and the file `psa_latlong.csv` provides geographical information about the parking machines within the parkzones.\n",
    "\n",
    "The parking data provided is genuine raw data and comes directly from the city of Göttingen. We have only added the geographical information. \n",
    "\n",
    "*Please note:*\n",
    "- *in the following the term \"parking ticket\" refers to a piece of paper that entitles you to park and not a fine for illegal parking.*\n",
    "- *although we only have data from February to December, we will refer to all data available as yearly.*\n",
    "- *due to the size of the data it might be necessary to use your memory efficiently, therefore avoid storing several copies of the same DataFrame.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.1 - Data Loading (10 points)\n",
    "Load the files for the machines (`Cale-*`) and for the app (`Parkster-*`) and concatenate all months to get two DataFrames, one for the machine and one for the app purchase for the whole year.\n",
    "Also load the machine (`psa_latlong.csv`) and the parkzone information (`parkzones_latlong.csv`).\n",
    "\n",
    "You will find the values `0` and `999` in the `Automaten ID` column for the machine data. Change the `0`s to `1`s and drop all entries with `999`.\n",
    "Also check whether there are any duplicate rows and delete them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.2 - Merging and Formating (12 points)\n",
    "Concatenate the app and machine data, using the parkzones *(in `parkzones_latlong.csv`)* and the parking machine number *(in `psa_latlong.csv`)*. Make sure that you have the geographical information for both, the parking machines and the parkzones, in the final data frame. \n",
    "Use the columns `Kaufdatum Lokal` and `Start` for the date of purchase, encode the column as a `datetime` object and use it as index column. Also make sure that the other columns have a reasonable data format. \n",
    "\n",
    "\n",
    "*Note: Having `NaN` values for some columns in the rows belonging to app purchases can be expected.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.3 - DataFrame Check (2 points)\n",
    "The cleaned and complete DataFrame for the following exercises should look like `data/clean_dataframe.csv`, which can be read in correctly as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('data/clean_dataframe.csv', parse_dates=['time'], index_col='time', dtype={'machine_ID': 'Int64', \n",
    "                                                                           'fee': 'float64', \n",
    "                                                                           'category': 'object', \n",
    "                                                                           'street': 'object', \n",
    "                                                                           'latitude_machine': 'float64', \n",
    "                                                                           'longitude_machine': 'float64', \n",
    "                                                                           'zone': 'int64', \n",
    "                                                                           'latitude_zone': 'float64', \n",
    "                                                                           'longitude_zone': 'float64'}).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that your DataFrame aligns with `clean_dataframe.csv`. To prove this, use the function [`pandas.DataFrame.equals`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.equals.html).\n",
    "\n",
    "If `pandas.DataFrame.equals` does not return `True`, please continue working with `clean_dataframe.csv` and indicate this using a Markdown cell. In that case you won't get any points for this subtask."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "## Exercise 2: Plotting (38 points)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.1 - Analysis of Parking Machines (11 points)\n",
    "The city of Göttingen would like to have an overview of the returns of the **individual parking machines** and hires you to carry out an initial explorative analysis of the sales volume and the geographical location of the machines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 (6 points)\n",
    "Find the top 5 parking machines regarding their sales volume in 2023 and plot their weekly turnover over the year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 (5 points)\n",
    "The location of the machines might also have an influence on the turnover. \n",
    "\n",
    "Familiarize yourself with the function `plot_map` from the library `dsplotter`. Use the function to plot the yearly turnover for each location. Make the color **and** the radius of the location marker dependent on the yearly turnover. Can you see any relationship between the machines with a high yearly turnover? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.2 - Analysis of Machine and App Usage per Zone (27 points)\n",
    "As part of the city's digitization initiative, the Parkster app was introduced a few years ago as an alternative to parking machines. \n",
    "So far we have focused only on the parking machines and therefore discarded a bulk of ticket sales.\n",
    "The city would like to carry out an initial visual analysis of the acceptance of the app in the individual parkzones in 2023 and analysis the total parking turnover. \n",
    "\n",
    "*Note that we can only analyse the total parking ticket sales by summarizing all parking machines per parkzone.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 (6 points)\n",
    "Do users prefer the app or the machine usage? \n",
    "\n",
    "Use an appropriate plot to show the average machine or app usage rate per **parkzone** for the whole year of 2023. What do you observe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 (9 points)\n",
    "How frequently are the individual parkzones used? \n",
    "\n",
    "Visualize the total number of parking tickets and the machine usage for each parkzone in 2023 in one plot. Use the a `log`-scale for the y-axis. What do you observe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.3 (7 points)\n",
    "The previous plot gives us an idea about the total number of *users* per parkzone. This number is likely highly correlated with the number of parking lots per zone. If we want to compare different parkzones with regard to their parking tickets sold, we should normalize them by the number of parking lots available. This way we can find out which zones are used most frequently. Because we don't have the number of parking lots available for each zone, we can only use the number of parking machines as a rough approximation for their sizes. \n",
    "\n",
    "Use the information from the `psa_latlong.csv` and reproduce the previous plot using the number of parking tickets normalized by the number of machines for each zone. Use the a `log`-scale for the y-axis.\n",
    "Which parkzone is the busiest one?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.4 (5 points)\n",
    "So far we haven't used the geographical information of the parkzones. \n",
    "\n",
    "Use the `plot_map`-function to plot the location (center) of all parkzones, their average tickets sold per machine and the rate of machine users. Color the location by the rate of machine users and set the radius using the tickets sold per machine. What do you observe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Exercise 3: Statistics (18 points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3.1 - t-Test (13 points)\n",
    "In addition to our visual analysis, we now also want to carry out a statistical study of machine vs. app usage.\n",
    "\n",
    "To do this, determine the daily rate of machine use per parkzone. Carry out a t-test **for each parkzone**, which statistically tests whether parkers prefer to use the app in the respective zone. Write down the corresponding pair of hypotheses, carry out the test and interpret your test results. Use a significance level of 0.05 for your test decision. Which fundamental assumption of the statistical test could be violated?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3.2 - Statistical Reasoning (5 points)\n",
    "Assume that for zone `37106` the rate of app users (and thus the rate of machine users) is `0.5`. \n",
    "The city sends you the data for 2024. \n",
    "\n",
    "How many days can you expect the app usage rate to be significantly greater than the machine usage rate at a significance level of 5%? Explain why that is the case. Assume that the behavior of the users has not changed compared to 2023."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Exercise 4: Machine Learning (20 points)\n",
    "\n",
    "Use the k-Nearest Neighbors (k-NN) algorithm to build a machine learning model that predicts the parking method (app or machine) based on location and fee as input features. Use parking data between fee value 2 euros and 7 euros.\n",
    "\n",
    "#### Excersice 4.1 - Model Building and Hyperparameter Search (10 points)\n",
    "Preprocess the data appropriately, perform hyperparameter search with cross validation for the optimal k value, visualize your optimal choice of k and finally use your optimal k-value to build the model.\n",
    "\n",
    "**Hint:** Use 30% of all the data to speed up hyperparameter search and use the whole dataset for model building\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 4.2 - Visualizing Model Predictions (10 points)\n",
    "Create a `100 x 100` grid of longitude/latitude values using the min and max values from your dataset and visualize the predictions of the k-NN model **for three different parking fees** - 3, 5, and 7 euros, using the `plot_map` function. Set the color of the markers on the map to your prediction. Point out at least 2 visual changes in the predicted pattern of parking method across the city for these three different fee values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
